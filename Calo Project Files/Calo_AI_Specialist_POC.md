# Calo AI Specialist POC - Subscription Growth Agent

## Executive Summary
- Reduce churn risk visibility from hours to seconds.
- Generate tailored Arabic or UK English offers with a single click.
- Keep outputs automation ready using a JSON block while showing a clean human plan.
- Model choice stays flexible via Hugging Face Inference Router.

# Architecture and Design

- Frontend - Streamlit single file app with three tabs: Data, Scoring, Recommendations.
- Data - CSV upload or synthetic generator with realistic distributions for last_order_days, orders_month, lifetime_months.
- Risk Model - Simple interpretable score combined and normalised to 0-100.
- LLM Layer - Hugging Face Inference Router with OpenAI compatible client. Default model gpt-oss-120b from Fireworks.
- Output Contract - Human plan text plus machine JSON. UI renders plan with bold emphasis while JSON stays internal.
- i18n - Arabic RTL and UK English LTR with CSS toggles and language switcher.


# Product Requirements Document - Subscription Growth Agent

## Problem
Meal subscriptions face churn due to waning engagement. Teams need a fast way to spot at-risk users and push the right offer at the right time without manual analysis.

## Goals
- Identify top at-risk subscribers in seconds.
- Generate human readable plan text plus structured JSON for automation.
- Support Arabic Gulf tone and UK English tone with a single codebase.
- Keep the model choice abstract through the HF Inference Router.

## Non-goals
- No PII ingestion in this POC.
- No production CRM integration in this POC.

## Users and Personas
- Retention Marketer - wants targeted offers and copy quickly.
- CRM Operator - needs structured payloads for campaigns.
- Growth PM - wants measurable lift and iteration speed.

## User Flow
1. Load or generate sample data.
2. Review data quality tips.
3. Calculate churn and select top N.
4. Generate AI recommendations.
5. Read plan text and inspect per-customer actions.
6. Export or plug into CRM in a next iteration.

## Functional Requirements
- Upload CSV with required schema.
- Create synthetic dataset when needed.
- Compute churn_score in range 0 to 100.
- Select top N customers: 5 or 10 or 15 or 20.
- Generate bilingual plan and JSON block based on language.
- Render bold emphasis for offers and percentages.
- Show per customer expander with message, expected impact, rationale.

## Acceptance Criteria
- With sample data, generation completes under 5 seconds locally.
- Plan text renders with consistent spacing and visible bold.
- JSON is parsed and drives the recommendation UI without exposing raw JSON.
- Switching language updates UI labels and sample data language.

## Metrics
- Time to first recommendation.
- CTR proxy: count of high impact offers.
- Recall of risky customers vs. baseline heuristic.

## Risks
- Model variance - mitigated by fixed prompts and constrained outputs.
- JSON parsing - mitigated by dual extraction of <JSON> or bare array.
- UI RTL LTR styling - mitigated by conditional CSS blocks.

## Next Steps
- Connect to CRM segments and A B tests.
- Add guardrails and observability.
- Introduce configurable weights for churn once validated.


# Prompts

## System - Arabic Gulf
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ³ÙˆÙŠÙ‚ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆÙ…Ø®ØµØµ Ù„Ø¯ÙˆÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬. Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø±Ø³Ø§Ù„Ø© ÙˆØ¯ÙŠØ© ÙˆÙ…Ù‡Ù†ÙŠØ©.

## User - Arabic Gulf
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„Ù‡Ø¬Ø©: {dialect}. 1) Ø§ÙƒØªØ¨ ÙÙ‚Ø±Ø© ÙˆØ¯ÙŠØ© Ù‚ØµÙŠØ±Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„ÙƒÙ„ Ø¹Ù…ÙŠÙ„ ØªØ´Ø±Ø­ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚ØªØ±Ø­ Ù…Ø¹ Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ©.
2) Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ‚Ø±Ø§ØªØŒ Ø£Ø¶Ù ÙƒØªÙ„Ø© <JSON>...</JSON> ÙÙŠÙ‡Ø§ Ù…ØµÙÙˆÙØ© ÙƒØ§Ø¦Ù†Ø§Øª Ø¨Ø§Ù„Ø­Ù‚Ù„:
customer_id, action, message, expected_lift, rationale.
Ø§Ù„Ù‚ÙŠÙ… Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·ØŒ ÙˆØ·ÙˆÙ„ message â‰¤ 120 Ø­Ø±ÙÙ‹Ø§.
Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: {records}

## System - UK English
You are a marketing assistant specialised for the UK market. Write in professional yet warm UK English.

## User - UK English
1) For each customer, write a short friendly paragraph in English that explains the retention offer with emojis.
2) Then add a <JSON>...</JSON> block containing an array of objects with keys:
customer_id, action, message, expected_lift, rationale.
Use UK English tone. Message length â‰¤ 120 characters.
Customers: {records}


## 60s Demo Scripts
### English
60s Demo Script â€” English

Goal - show end to end value for Calo - reduce churn risk visibility and generate tailored offers in seconds.

0-5s
Voiceover: "Hi, I am [Your Name]. This is a 1 minute AI prototype for Calo focused on reducing churn and lifting repeat orders."
Action: Launch the app. App title visible.

5-12s
Voiceover: "I can switch Arabic or English. I will pick English for the UK market."
Action: Sidebar, choose Language -> English. Theme change optional.

12-18s
Voiceover: "Data can come from CSV or sample data. I will generate a clean sample."
Action: Click Generate sample data. Show table. Open "Data quality tips".

18-28s
Voiceover: "Next, we calculate churn risk."
Action: Open Scoring. "The score blends time since last order, order frequency, lifetime, and promo usage, then normalises 0 to 100."
Action: Select 10 in "Show top at-risk customers".

28-45s
Voiceover: "Now AI generates tailored retention offers."
Action: Go to Recommendations. Set top 5. Click "Generate retention recommendations".
Voiceover: "Under the hood I use Hugging Face Inference Router with an OpenAI compatible client calling GPT-OSS-120B. Data here is synthetic."

45-55s
Voiceover: "We get a clean plan plus structured JSON behind the scenes. Key parts are bold and each recommendation shows expected impact."
Action: Scroll the plan, expand two recommendations.

55-60s
Voiceover: "This can ship as a POC and plug into CRM and campaigns. Thank you."
Action: End on plan view.


### Arabic
Ù†Øµ Ø§Ù„Ø¯ÙŠÙ…Ùˆ 60 Ø«Ø§Ù†ÙŠØ© â€” Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

Ø§Ù„Ù‡Ø¯Ù - Ø¥Ø¸Ù‡Ø§Ø± Ù‚ÙŠÙ…Ø© ÙÙˆØ±ÙŠØ© Ù„ÙƒØ§Ù„Ùˆ - Ø±Ø¤ÙŠØ© ÙˆØ§Ø¶Ø­Ø© Ù„Ø®Ø·Ø± Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨ ÙˆØªÙˆÙ„ÙŠØ¯ Ø¹Ø±ÙˆØ¶ Ù…Ø®ØµØµØ© Ø®Ù„Ø§Ù„ Ø«ÙˆØ§Ù†Ù.

0-5 Ø«
Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ: "Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø£Ù†Ø§ [Ø§Ø³Ù…Ùƒ]. Ù‡Ø°Ø§ Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø³Ø±ÙŠØ¹ Ù„Ù…Ø¯Ø© Ø¯Ù‚ÙŠÙ‚Ø© ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ø®ÙØ¶ Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨ ÙˆØ²ÙŠØ§Ø¯Ø© ØªÙƒØ±Ø§Ø± Ø§Ù„Ø·Ù„Ø¨."
Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ¸Ù‡ÙˆØ± Ø§Ù„Ø¹Ù†ÙˆØ§Ù†.

5-12 Ø«
Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ: "Ø£Ø¨Ø¯Ù‘Ù„ Ø¨ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©. Ø³Ø£Ø®ØªØ§Ø± Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠ."
Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø§Ø®ØªÙŠØ§Ø± English. ØªØºÙŠÙŠØ± Ø§Ù„Ù„ÙˆÙ† Ø§Ø®ØªÙŠØ§Ø±ÙŠ.

12-18 Ø«
Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ: "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CSV Ø£Ùˆ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©. Ø³Ø£ÙˆÙ„Ù‘Ø¯ Ø¹ÙŠÙ†Ø© Ù†Ù‚ÙŠØ©."
Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: Ø¶ØºØ· "Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©". Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„. ÙØªØ­ "Ù†ØµØ§Ø¦Ø­ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª".

18-28 Ø«
Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ: "Ø§Ù„Ø¢Ù† Ù†Ø­Ø³Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨."
Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: ÙØªØ­ ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø­Ø³Ø§Ø¨. "Ø§Ù„Ø¯Ø±Ø¬Ø© ØªÙ…Ø²Ø¬ ØªØ£Ø®Ø± Ø¢Ø®Ø± Ø·Ù„Ø¨ ÙˆØªÙƒØ±Ø§Ø± Ø§Ù„Ø´Ø±Ø§Ø¡ ÙˆØ·ÙˆÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ø±ÙˆØ¶ Ø«Ù… Ù†Ø·Ø¨Ù‘Ø¹Ù‡Ø§ Ù…Ù† 0 Ø¥Ù„Ù‰ 100."
Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: Ø§Ø®ØªÙŠØ§Ø± 10 Ù…Ù† "Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø®Ø·Ø±Ø§Ù‹".

28-45 Ø«
Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ: "Ù†ÙˆÙ„Ù‘Ø¯ Ø¹Ø±ÙˆØ¶ Ø§Ø­ØªÙØ§Ø¸ Ù…Ø®ØµØµØ©."
Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª. Ø§Ø®ØªÙŠØ§Ø± Ø£Ø¹Ù„Ù‰ 5. Ø¶ØºØ· "ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø­ØªÙØ§Ø¸".
Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ: "ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© Ù†Ø³ØªØ®Ø¯Ù… Hugging Face Inference Router Ø¨ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ OpenAI ÙˆÙ†Ù…ÙˆØ°Ø¬ GPT-OSS-120B. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©."

45-55 Ø«
Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ: "ØªØ¸Ù‡Ø± Ø®Ø·Ø© Ù…Ù†Ø³Ù‚Ø© Ù…Ø¹ Ø¥Ø¨Ø±Ø§Ø² Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø®Ø· Ø¹Ø±ÙŠØ¶ ÙˆÙ„ÙƒÙ„ ØªÙˆØµÙŠØ© ØªØ£Ø«ÙŠØ± Ù…ØªÙˆÙ‚Ù‘Ø¹."
Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø®Ø·Ø© ÙˆØªÙˆØ³ÙŠØ¹ ØªÙˆØµÙŠØªÙŠÙ†.

55-60 Ø«
Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØµÙˆØªÙŠ: "Ø¬Ø§Ù‡Ø²Ø© ÙƒØ¥Ø«Ø¨Ø§Øª Ù…ÙÙ‡ÙˆÙ… ÙˆÙŠÙ…ÙƒÙ† Ø±Ø¨Ø·Ù‡Ø§ Ù…Ø¹ CRM ÙˆØ§Ù„Ø­Ù…Ù„Ø§Øª. Ø´ÙƒØ±Ø§Ù‹."
Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: Ø¥Ù†Ù‡Ø§Ø¡ Ø¹Ù„Ù‰ Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø·Ø©.


## Full Source Code
```python
# app.py
# export HF_TOKEN="hf_..."
# streamlit run app.py

import os
import re
import json
import html
import streamlit as st
import pandas as pd
import numpy as np
from openai import OpenAI

# -----------------------------
# Settings
# -----------------------------
HF_ROUTER = "https://router.huggingface.co/v1"
DEFAULT_MODEL = "openai/gpt-oss-120b:fireworks-ai"


# -----------------------------
# Client and state
# -----------------------------
def make_client() -> OpenAI:
    token = os.environ.get("HF_TOKEN")
    if not token:
        raise EnvironmentError("HF_TOKEN not set. Please set your Hugging Face token.")
    return OpenAI(base_url=HF_ROUTER, api_key=token)


def init_state():
    if "model" not in st.session_state:
        st.session_state.model = DEFAULT_MODEL
    if "plan_text" not in st.session_state:
        st.session_state.plan_text = ""
    if "parsed_recs" not in st.session_state:
        st.session_state.parsed_recs = None
    if "lang" not in st.session_state:
        st.session_state.lang = "Arabic"
    if "dialect" not in st.session_state:
        st.session_state.dialect = "Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ©"


# -----------------------------
# LLM helpers
# -----------------------------
def extract_text_from_completion(completion) -> str:
    try:
        choices = getattr(completion, "choices", None) or completion.get("choices")
        first = choices[0]
        msg = getattr(first, "message", None) or first.get("message")
        if isinstance(msg, dict):
            return msg.get("content", "")
        return getattr(msg, "content", "") or getattr(first, "text", "") or ""
    except Exception:
        try:
            return json.dumps(completion, ensure_ascii=False)
        except Exception:
            return str(completion)


def split_natural_and_json(full_text: str):
    if not full_text:
        return "", None
    m = re.search(r"<JSON>([\s\S]*?)</JSON>", full_text, re.IGNORECASE)
    if m:
        natural = (full_text[:m.start()] + full_text[m.end():]).strip()
        return natural, m.group(1).strip()
    m2 = re.search(r"(\{[\s\S]*?\}|\[[\s\S]*?\])", full_text)
    if m2:
        json_text = m2.group(1).strip()
        natural = (full_text[:m2.start()] + full_text[m2.end():]).strip()
        return natural, json_text
    return full_text, None


# -----------------------------
# Data helpers
# -----------------------------
def validate_uploaded_df(df: pd.DataFrame):
    required = {
        "customer_id",
        "last_order_days",
        "avg_spend",
        "orders_month",
        "lifetime_months",
        "preference",
        "promo_used_recently",
    }
    missing = [c for c in required if c not in df.columns]
    if missing:
        return ("Missing columns: " if st.session_state.lang == "English" else "Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ©: ") + ", ".join(missing)
    return None


def generate_sample_subscribers(n=60, lang="Arabic"):
    np.random.seed(42)
    prefs = (
        ["Ù†Ø¨Ø§ØªÙŠ", "Ù†Ø¨Ø§ØªÙŠ ØµØ§Ø±Ù…", "Ù…Ø­Ø¨ Ø§Ù„Ù„Ø­ÙˆÙ…", "Ù…Ù†Ø®ÙØ¶ Ø§Ù„ÙƒØ±Ø¨ÙˆÙ‡ÙŠØ¯Ø±Ø§Øª", "Ù…ØªÙˆØ§Ø²Ù†"]
        if lang == "Arabic"
        else ["Vegetarian", "Vegan", "Meat Lover", "Low Carb", "Balanced"]
    )
    rows = []
    for i in range(1, n + 1):
        last_order_days = int(np.clip(np.random.exponential(12), 0, 120))
        avg_spend = round(np.random.uniform(1.5, 10), 2)
        orders_month = int(np.random.poisson(3))
        lifetime_months = int(np.random.exponential(8))
        pref = np.random.choice(prefs)
        promo_used = np.random.choice([0, 1], p=[0.7, 0.3])
        rows.append(
            {
                "customer_id": f"C{i:04d}",
                "last_order_days": last_order_days,
                "avg_spend": avg_spend,
                "orders_month": orders_month,
                "lifetime_months": lifetime_months,
                "preference": pref,
                "promo_used_recently": int(promo_used),
            }
        )
    return pd.DataFrame(rows)


def churn_score(df: pd.DataFrame) -> pd.Series:
    score = (
        (df["last_order_days"] * 1.5)
        - (df["orders_month"] * 8)
        - (df["lifetime_months"] * 0.5)
        + (5 * (1 - (df["promo_used_recently"])))
    ) / (df["avg_spend"] + 1)
    s = 100 * (score - score.min()) / (score.max() - score.min() + 1e-6)
    return s.round(1)


# -----------------------------
# UI styling and rendering
# -----------------------------
def style_primary(color: str, lang: str):
    direction_css = (
        """
        .stApp { direction: rtl; }
        .stMarkdown, .stText { text-align: right; }
        [data-testid="stSidebar"] { direction: rtl; }
        """
        if lang == "Arabic"
        else """
        .stApp { direction: ltr; }
        .stMarkdown, .stText { text-align: left; }
        [data-testid="stSidebar"] { direction: ltr; }
        """
    )
    st.markdown(
        f"""
        <style>
        {direction_css}
        body, div, p, span {{
            font-family: "Tajawal","Cairo","Noto Kufi Arabic","Segoe UI",Arial,sans-serif;
        }}
        div.stButton>button {{
            background: {color};
            color: white;
            border-radius: 8px;
            border: 0;
            padding: 0.5rem 0.8rem;
        }}
        .highlight {{
            background: rgba(0,0,0,0.03);
            padding: 0.9rem 1.1rem;
            border-radius: 10px;
            border: 1px solid #eee;
        }}
        .plan-wrapper {{
            background: #ffffff;
            border: 1px solid #eee;
            border-radius: 12px;
            padding: 1rem 1.25rem;
        }}
        .plan-wrapper h3 {{
            margin: 0 0 12px 0;
            font-weight: 700;
        }}
        .plan-line {{
            line-height: 1.9;
            margin: 0 0 8px 0;
            font-size: 1.05rem;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )


def render_bold(text: str) -> str:
    esc = html.escape(text)
    esc = re.sub(r"\*\*(.+?)\*\*", r"<strong>\1</strong>", esc)
    esc = re.sub(r"__(.+?)__", r"<strong>\1</strong>", esc)
    esc = re.sub(r"(\d+(?:\.\d+)?\s*[Ùª%])", r"<strong>\1</strong>", esc)
    for pat in [r"\bdiscount\b", r"\boffer\b", r"\bfree\s+(?:delivery|shipping)\b", r"\bvoucher\b", r"\bcoupon\b", r"\bpromo\b", r"\bcode\b", r"\bpoints?\b", r"\bdouble\s+points?\b", r"\bsave\b"]:
        esc = re.sub(pat, lambda m: f"<strong>{m.group(0)}</strong>", esc, flags=re.IGNORECASE)
    for pat in [r"Ø®ØµÙ…", r"Ø¹Ø±Ø¶", r"ÙƒÙˆØ¨ÙˆÙ†", r"Ù‚Ø³ÙŠÙ…Ø©", r"Ø±Ù…Ø²", r"Ù†Ù‚Ø§Ø·", r"Ù…Ø¶Ø§Ø¹ÙØ©\s+Ø§Ù„Ù†Ù‚Ø§Ø·", r"(?:ØªÙˆØµÙŠÙ„|Ø´Ø­Ù†)\s+Ù…Ø¬Ø§Ù†ÙŠ", r"Ù…Ø¬Ø§Ù†ÙŠ"]:
        esc = re.sub(pat, lambda m: f"<strong>{m.group(0)}</strong>", esc)
    return esc


def render_plan_text(text: str, lang: str) -> str:
    lines = [ln.strip() for ln in text.splitlines()]
    cleaned = [l for l in lines if l]
    paras_html = [f"<p class='plan-line'>{render_bold(l)}</p>" for l in cleaned]
    title = "Plan - English text" if lang == "English" else "Ø§Ù„Ø®Ø·Ø© - Ù†Øµ Ø¹Ø±Ø¨ÙŠ"
    return f"<div class='plan-wrapper'><h3>{title}</h3>{''.join(paras_html)}</div>"


# -----------------------------
# Sidebar
# -----------------------------
def sidebar(lang: str):
    st.header("Settings" if lang == "English" else "Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")

    lang_choice = st.radio("Language / Ø§Ù„Ù„ØºØ©", ["Arabic", "English"], index=0 if lang == "Arabic" else 1)
    st.session_state.lang = lang_choice
    lang = lang_choice

    if lang == "Arabic":
        st.session_state.dialect = st.selectbox("Ø§Ù„Ù„Ù‡Ø¬Ø©", ["Ø§Ù„ÙØµØ­Ù‰", "Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ©"], index=1)

    if lang == "English":
        theme = st.selectbox("Theme color", ["Green", "Blue", "Purple"])
        color_map = {"Green": "#22c55e", "Blue": "#3b82f6", "Purple": "#8b5cf6"}
    else:
        theme = st.selectbox("Ù„ÙˆÙ† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©", ["Ø£Ø®Ø¶Ø±", "Ø£Ø²Ø±Ù‚", "Ø¨Ù†ÙØ³Ø¬ÙŠ"])
        color_map = {"Ø£Ø®Ø¶Ø±": "#22c55e", "Ø£Ø²Ø±Ù‚": "#3b82Ù6", "Ø¨Ù†ÙØ³Ø¬ÙŠ": "#8b5cf6"}

    style_primary(color_map.get(theme, "#22c55e"), lang)

    st.session_state.model = st.text_input("Model ID" if lang == "English" else "Ù…Ø¹Ø±Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", value=st.session_state.model)

    st.markdown("**Data source**" if lang == "English" else "**Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**")
    uploaded = st.file_uploader("Upload CSV" if lang == "English" else "Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV", type=["csv"])
    if uploaded is not None:
        try:
            up_df = pd.read_csv(uploaded)
            err = validate_uploaded_df(up_df)
            if err:
                st.error(err)
            else:
                st.session_state["subscribers_df"] = up_df
                st.success("CSV uploaded successfully." if lang == "English" else "ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª CSV Ø¨Ù†Ø¬Ø§Ø­.")
        except Exception as e:
            st.error(("Failed to upload file: " if lang == "English" else "ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: ") + str(e))

    if st.button("Generate sample data" if lang == "English" else "Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©"):
        st.session_state["subscribers_df"] = generate_sample_subscribers(lang=lang)

    if st.button("Clear data" if lang == "English" else "Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        st.session_state.pop("subscribers_df", None)
        st.session_state.plan_text = ""
        st.session_state.parsed_recs = None
        st.success("Cleared." if lang == "English" else "ØªÙ… Ø§Ù„Ù…Ø³Ø­.")


# -----------------------------
# Tabs
# -----------------------------
def tab_data_view(df: pd.DataFrame, lang: str):
    st.subheader("Data preview" if lang == "English" else "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    st.dataframe(df, use_container_width=True)
    with st.expander("Data quality tips" if lang == "English" else "Ù†ØµØ§Ø¦Ø­ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        st.markdown(
            "- Ensure all required columns exist.\n- Boolean values like promo_used_recently must be 0 or 1.\n- Numeric columns should not contain text."
            if lang == "English"
            else "- ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.\n- Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© ÙƒÙ€ promo_used_recently ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† 0 Ø£Ùˆ 1.\n- Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø¨Ø¯ÙˆÙ† Ù‚ÙŠÙ… Ù†ØµÙŠØ©."
        )


def tab_scoring_view(df: pd.DataFrame, lang: str):
    st.subheader("Churn score calculation" if lang == "English" else "Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨")
    try:
        df["churn_score"] = churn_score(df)
    except Exception as e:
        st.error(f"Failed to calculate churn score: {e}" if lang == "English" else f"ØªØ¹Ø°Ø± Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨: {e}")
        st.stop()

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Customers" if lang == "English" else "Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡", len(df))
    c2.metric("Avg score" if lang == "English" else "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ø±Ø¬Ø©", f"{df['churn_score'].mean():.1f}%")
    c3.metric("Max score" if lang == "English" else "Ø£Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø©", f"{df['churn_score'].max():.1f}%")
    c4.metric("Min score" if lang == "English" else "Ø£Ø¯Ù†Ù‰ Ø¯Ø±Ø¬Ø©", f"{df['churn_score'].min():.1f}%")

    top_n = st.selectbox("Show top at-risk customers" if lang == "English" else "Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø®Ø·Ø±Ø§Ù‹", [5, 10, 15, 20], index=0)

    st.dataframe(
        df.sort_values("churn_score", ascending=False).head(top_n),
        use_container_width=True,
        column_config={
            "churn_score": st.column_config.ProgressColumn(
                "Churn score" if lang == "English" else "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨",
                help="Relative score 0 to 100" if lang == "English" else "Ù‚ÙŠÙ…Ø© Ù†Ø³Ø¨ÙŠØ© Ù…Ù† 0 Ø¥Ù„Ù‰ 100",
                min_value=0,
                max_value=100,
                format="%.1f%%",
            )
        },
    )

    with st.expander("How churn score is calculated" if lang == "English" else "ÙƒÙŠÙ Ù†Ø­Ø³Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨"):
        st.markdown(
            "Composite score: longer since last order raises risk, frequent monthly orders and long lifetime reduce risk, and recent promo use reduces risk. Normalised to 0 to 100."
            if lang == "English"
            else "Ù†Ø­Ø³Ø¨ Ø¯Ø±Ø¬Ø© Ù…Ø±ÙƒØ¨Ø© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø¹ÙˆØ§Ù…Ù„: ØªØ£Ø®Ø± Ø¢Ø®Ø± Ø·Ù„Ø¨ ÙŠØ±ÙØ¹ Ø§Ù„Ø®Ø·Ø±ØŒ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø´Ø±Ø§Ø¡ ÙˆØ·ÙˆÙ„ Ø§Ù„Ø¹Ù…Ø± ÙŠÙ‚Ù„Ù„Ø§Ù† Ø§Ù„Ø®Ø·Ø±ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø±Ø¶ ØªØ±ÙˆÙŠØ¬ÙŠ Ù…Ø¤Ø®Ø±Ø§Ù‹ ÙŠÙ‚Ù„Ù„ Ø§Ù„Ø®Ø·Ø±. Ù†Ø·Ø¨Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ Ù†Ø·Ø§Ù‚ 0 Ø­ØªÙ‰ 100."
        )


def _emoji_for_lift(lift: str) -> str:
    s = str(lift or "").strip().lower()
    if s in ["high", "Ø¹Ø§Ù„ÙŠ", "Ù…Ø±ØªÙØ¹"]:
        return "ğŸ”¥"
    if s in ["medium", "Ù…ØªÙˆØ³Ø·"]:
        return "ğŸ‘"
    if s in ["low", "Ù…Ù†Ø®ÙØ¶"]:
        return "ğŸ””"
    return "ğŸ“ˆ"


def tab_recommendations_view(df: pd.DataFrame, lang: str, dialect: str):
    st.subheader("Generate recommendations" if lang == "English" else "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª")

    df_scored = df.copy()
    if "churn_score" not in df_scored.columns:
        df_scored["churn_score"] = churn_score(df_scored)

    top_k = st.selectbox("Number of top at-risk customers" if lang == "English" else "Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø®Ø·Ø±Ø§Ù‹", [5, 10, 15, 20], index=0)

    selected = df_scored.sort_values("churn_score", ascending=False).head(top_k)
    st.dataframe(
        selected[["customer_id", "last_order_days", "orders_month", "avg_spend", "churn_score"]],
        use_container_width=True,
        column_config={
            "churn_score": st.column_config.ProgressColumn(
                "Churn score" if lang == "English" else "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨",
                min_value=0,
                max_value=100,
                format="%.1f%%",
            )
        },
    )

    if st.button("Generate retention recommendations" if lang == "English" else "ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø­ØªÙØ§Ø¸"):
        top_records = selected.to_dict(orient="records")

        if lang == "Arabic":
            sys_prompt = "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ³ÙˆÙŠÙ‚ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆÙ…Ø®ØµØµ Ù„Ø¯ÙˆÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬. Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø±Ø³Ø§Ù„Ø© ÙˆØ¯ÙŠØ© ÙˆÙ…Ù‡Ù†ÙŠØ©."
            user_prompt = (
                f"Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„Ù‡Ø¬Ø©: {dialect}. "
                "1) Ø§ÙƒØªØ¨ ÙÙ‚Ø±Ø© ÙˆØ¯ÙŠØ© Ù‚ØµÙŠØ±Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„ÙƒÙ„ Ø¹Ù…ÙŠÙ„ ØªØ´Ø±Ø­ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚ØªØ±Ø­ Ù…Ø¹ Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ©. "
                "2) Ø¨Ø¹Ø¯ Ø§Ù„ÙÙ‚Ø±Ø§ØªØŒ Ø£Ø¶Ù ÙƒØªÙ„Ø© <JSON>...</JSON> ÙÙŠÙ‡Ø§ Ù…ØµÙÙˆÙØ© ÙƒØ§Ø¦Ù†Ø§Øª Ø¨Ø§Ù„Ø­Ù‚Ù„: "
                "customer_id, action, message, expected_lift, rationale. "
                "Ø§Ù„Ù‚ÙŠÙ… Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·ØŒ ÙˆØ·ÙˆÙ„ message â‰¤ 120 Ø­Ø±ÙÙ‹Ø§. "
                f"Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: {json.dumps(top_records, ensure_ascii=False)}"
            )
        else:
            sys_prompt = "You are a marketing assistant specialised for the UK market. Write in professional yet warm UK English."
            user_prompt = (
                "1) For each customer, write a short friendly paragraph in English that explains the retention offer with emojis. "
                "2) Then add a <JSON>...</JSON> block containing an array of objects with keys: "
                "customer_id, action, message, expected_lift, rationale. "
                "Use UK English tone. Message length â‰¤ 120 characters. "
                f"Customers: {json.dumps(top_records, ensure_ascii=False)}"
            )

        with st.spinner("Generating plan and recommendations..." if lang == "English" else "Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø®Ø·Ø© ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª"):
            try:
                client = make_client()
                completion = client.chat.completions.create(
                    model=st.session_state.model,
                    messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": user_prompt}],
                )
                full_text = extract_text_from_completion(completion)
                natural, json_text = split_natural_and_json(full_text)

                if natural:
                    st.session_state.plan_text = natural

                parsed = None
                if json_text:
                    try:
                        parsed = json.loads(json_text)
                    except Exception:
                        parsed = None
                        st.warning("Could not parse JSON." if lang == "English" else "ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© JSON.")
                st.session_state.parsed_recs = parsed
                st.success("Generated successfully." if lang == "English" else "ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­.")
            except Exception as e:
                st.error(("Failed: " if lang == "English" else "ÙØ´Ù„: ") + str(e))

    if st.session_state.plan_text:
        st.markdown(render_plan_text(st.session_state.plan_text, lang), unsafe_allow_html=True)

    if isinstance(st.session_state.parsed_recs, list):
        st.markdown("### Recommendations" if lang == "English" else "### Ø§Ù„ØªÙˆØµÙŠØ§Øª")
        for rec in st.session_state.parsed_recs:
            cid = rec.get("customer_id", "-")
            action = rec.get("action", "")
            message_raw = rec.get("message", "")
            lift = rec.get("expected_lift", "")
            rationale = rec.get("rationale", "")
            emoji = _emoji_for_lift(lift)

            with st.expander(f"{emoji} {cid} - {action}"):
                st.markdown(("**Message:** " if lang == "English" else "**Ø§Ù„Ø±Ø³Ø§Ù„Ø©:** ") + render_bold(message_raw), unsafe_allow_html=True)
                st.markdown(("**Expected impact:** " if lang == "English" else "**Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:** ") + f"**{html.escape(str(lift))}**")
                if rationale:
                    st.markdown(("**Rationale:** " if lang == "English" else "**Ø§Ù„Ø³Ø¨Ø¨:** ") + html.escape(str(rationale)))


# -----------------------------
# App
# -----------------------------
def app():
    st.set_page_config(page_title="Subscription Growth Agent", layout="wide", initial_sidebar_state="expanded")
    init_state()

    with st.sidebar:
        sidebar(st.session_state.lang)

    if st.session_state.lang == "English":
        st.title("ğŸŒ Subscription Growth Agent - Calo")
        st.markdown("ğŸ¤– Helps identify at-risk customers and generate retention recommendations.")
    else:
        st.title("ğŸŒ ÙˆÙƒÙŠÙ„ Ù†Ù…Ùˆ Ø§Ù„Ø§Ø´ØªØ±Ø§ÙƒØ§Øª - Calo")
        st.markdown("ğŸ¤– ÙŠØ³Ø§Ø¹Ø¯ Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø°ÙˆÙŠ Ø®Ø·Ø± Ø§Ù„Ø§Ù†Ø³Ø­Ø§Ø¨ ÙˆØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.")

    if "subscribers_df" not in st.session_state:
        st.info("No data yet. Upload a CSV or generate sample data from the sidebar." if st.session_state.lang == "English" else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯. Ø§Ø±ÙØ¹ CSV Ø£Ùˆ Ø£Ù†Ø´Ø¦ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ.")
        st.stop()

    df = st.session_state["subscribers_df"]
    tabs = (["Data", "Scoring", "Recommendations"] if st.session_state.lang == "English" else ["Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„ØªÙˆØµÙŠØ§Øª"])
    tab_data, tab_scoring, tab_reco = st.tabs(tabs)

    with tab_data:
        tab_data_view(df, st.session_state.lang)
    with tab_scoring:
        tab_scoring_view(df, st.session_state.lang)
    with tab_reco:
        tab_recommendations_view(df, st.session_state.lang, st.session_state.dialect if st.session_state.lang == "Arabic" else "")


if __name__ == "__main__":
    try:
        app()
    except EnvironmentError as e:
        st.error(str(e))
    except Exception as e:
        st.exception(e)

```

# Alignment to Calo AI Specialist Role

- Agent development and prompt engineering - stable prompts produce both human plan and JSON payloads.
- POC prototyping - Streamlit app demonstrates end to end value in under 60 seconds.
- Data preparation - synthetic generator ensures safe demos with realistic fields.
- Model flexibility - HF Router keeps the app model agnostic for future swaps or fine tuned models.
- Knowledge sharing - PRD and demo script included for team handoff and lunch and learn sessions.


# Setup and Run

1. Install requirements:
   - streamlit, openai, pandas, numpy
2. Set environment variable:
   - export HF_TOKEN="hf_xxx"
3. Run:
   - streamlit run app.py
4. Optional:
   - Upload CSV with required columns or use sample data.

